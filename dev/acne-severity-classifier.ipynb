{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as skmetrics\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ['../data-collection/dataset/acne-severity/NNEW_trainval_0.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_trainval_1.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_trainval_2.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_trainval_3.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_trainval_4.txt']\n",
    "test_data = ['../data-collection/dataset/acne-severity/NNEW_test_0.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_test_1.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_test_2.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_test_3.txt',\n",
    "            '../data-collection/dataset/acne-severity/NNEW_test_4.txt']\n",
    "path = '../data-collection/dataset/acne-severity/JPEGImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Dataset:\n",
    "    def __init__(self, data, data_path, transform, training=True):\n",
    "        self.data = data\n",
    "        self.imgs = data['path'].unique().tolist()\n",
    "        self.data_path = data_path\n",
    "        self.training = training\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.data_path, self.data.iloc[idx, 0]))\n",
    "\n",
    "        if(self.training):\n",
    "            label = self.data.iloc[idx, 1]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if(self.training):\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(dataset, train_batch_size, validation_split=0.2):\n",
    "    # number of samples in train and test set\n",
    "    train_len = int(len(dataset) * (1 - validation_split))\n",
    "    test_len = len(dataset) - train_len\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len])\n",
    "    # create train_loader\n",
    "    print(len(train_set))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=train_batch_size, shuffle=True,\n",
    "    )\n",
    "    # create test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False,)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, data[\"label\"], test_size=test_size, stratify = data.iloc[:,1]\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, metric_names):\n",
    "        self.metric_names = metric_names\n",
    "        # initialize a metric dictionary\n",
    "        self.metric_dict = {metric_name: [0] for metric_name in self.metric_names}\n",
    "\n",
    "    def step(self, labels, preds):\n",
    "        for metric in self.metric_names:\n",
    "            # get the metric function\n",
    "            do_metric = getattr(\n",
    "                skmetrics, metric, \"The metric {} is not implemented\".format(metric)\n",
    "            )\n",
    "            # check if metric require average method, if yes set to 'micro' or 'macro' or 'None'\n",
    "            try:\n",
    "                self.metric_dict[metric].append(\n",
    "                    do_metric(labels, preds, average=\"macro\")\n",
    "                )\n",
    "            except:\n",
    "                self.metric_dict[metric].append(do_metric(labels, preds))\n",
    "\n",
    "    def epoch(self):\n",
    "        # calculate metrics for an entire epoch\n",
    "        avg = [sum(metric) / (len(metric) - 1) for metric in self.metric_dict.values()]\n",
    "        metric_as_dict = dict(zip(self.metric_names, avg))\n",
    "        return metric_as_dict\n",
    "\n",
    "    def last_step_metrics(self):\n",
    "        # return metrics of last steps\n",
    "        values = [self.metric_dict[metric][-1] for metric in self.metric_names]\n",
    "        metric_as_dict = dict(zip(self.metric_names, values))\n",
    "        return metric_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        target = F.one_hot(target, num_classes=pred.size(-1))\n",
    "        target = target.float()\n",
    "        target = (1 - self.smoothing) * target + self.smoothing / pred.size(-1)\n",
    "        log_pred = F.log_softmax(pred, dim=self.dim)\n",
    "        loss = nn.KLDivLoss(reduction='batchmean')(log_pred, target)\n",
    "        return loss\n",
    "    \n",
    "criterion = LabelSmoothingLoss(smoothing=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, test_loader, optimizer, criterion, train_metrics, val_metrics,):\n",
    "    # training-the-model\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move-tensors-to-GPU\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        # day = day.view(-1,1).type(torch.FloatTensor)\n",
    "        # target=torch.Tensor(target)\n",
    "        target = target.float()\n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        output = model(data)\n",
    "        preds = torch.argmax(output, axis=1).cpu().detach().numpy()\n",
    "        labels = target.cpu().numpy()\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(output.type(torch.FloatTensor), target.type(torch.LongTensor))\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "        # perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step()\n",
    "        # update-training-loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        # calculate training metrics\n",
    "        all_labels.extend(labels)\n",
    "        all_preds.extend(preds)\n",
    "    \n",
    "    train_metrics.step(all_labels, all_preds)\n",
    "\n",
    "    # validate-the-model\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            # day = day.view(-1,1).type(torch.FloatTensor)\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, axis=1).tolist()\n",
    "            labels = target.tolist()\n",
    "            all_labels.extend(labels)\n",
    "            all_preds.extend(preds)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # update-average-validation-loss\n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "    val_metrics.step(all_labels, all_preds)\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    valid_loss = valid_loss / len(test_loader.sampler)\n",
    "\n",
    "    return (\n",
    "        train_loss,\n",
    "        valid_loss,\n",
    "        train_metrics.last_step_metrics(),\n",
    "        val_metrics.last_step_metrics(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\269451781.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(train_data[0], names=['path','label','leisons'], sep='  ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data[0], names=['path','label','leisons'], sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_102.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>levle3_92.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>levle3_93.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>levle3_94.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>levle3_95.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>levle3_96.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                path  label  leisons\n",
       "0       levle0_0.jpg      0        3\n",
       "1       levle0_1.jpg      0        3\n",
       "2     levle0_100.jpg      0        2\n",
       "3     levle0_101.jpg      0        1\n",
       "4     levle0_102.jpg      0        3\n",
       "...              ...    ...      ...\n",
       "1160   levle3_92.jpg      3       63\n",
       "1161   levle3_93.jpg      3       61\n",
       "1162   levle3_94.jpg      3       58\n",
       "1163   levle3_95.jpg      3       58\n",
       "1164   levle3_96.jpg      3       57\n",
       "\n",
       "[1165 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = data_split(train_df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\722665227.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv(test_data[0],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_data[0],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_451.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_498.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_485.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_218.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle1_344.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>levle3_88.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>levle3_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>levle3_68.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>levle3_16.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>levle3_100.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  label  leisons\n",
       "0    levle0_451.jpg      0        2\n",
       "1    levle0_498.jpg      0        1\n",
       "2    levle0_485.jpg      0        3\n",
       "3    levle0_218.jpg      0        2\n",
       "4    levle1_344.jpg      0        4\n",
       "..              ...    ...      ...\n",
       "287   levle3_88.jpg      3       64\n",
       "288    levle3_1.jpg      3       60\n",
       "289   levle3_68.jpg      3       56\n",
       "290   levle3_16.jpg      3       65\n",
       "291  levle3_100.jpg      3       58\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                            torchvision.transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images left-right\n",
    "                            torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "                            torchvision.transforms.RandomRotation(degrees=15),\n",
    "                                            torchvision.transforms.ElasticTransform(),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Classification_Dataset(x_train,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=transform,training=True)\n",
    "val_dataset = Classification_Dataset(x_val,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "    )\n",
    "\n",
    "# create test_loader\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Classification_Dataset(test_df,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=1, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = Metrics([\"accuracy_score\",\"f1_score\"])\n",
    "val_metrics = Metrics([\"accuracy_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "     \n",
    "        self.cnn = torchvision.models.efficientnet_v2_m(pretrained=True)\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn.classifier = nn.Sequential(\n",
    "      \n",
    "        nn.Linear(self.cnn.classifier[1].in_features, 512),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 128),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128, 64),\n",
    "            nn.Linear(64, 4),     \n",
    "       )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        output = self.cnn(img)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prais\\Workspace\\AAIML\\Sem1\\MLFoundations\\CSCN8010-class-notebooks\\venv\\tensorflow_cpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prais\\Workspace\\AAIML\\Sem1\\MLFoundations\\CSCN8010-class-notebooks\\venv\\tensorflow_cpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0281,  0.0156,  0.0624, -0.0357],\n",
       "        [-0.0294,  0.0376,  0.0323, -0.0361],\n",
       "        [-0.0395,  0.0312,  0.0737, -0.0174],\n",
       "        [-0.0129,  0.0362,  0.0530, -0.0089],\n",
       "        [-0.0645,  0.0205,  0.0691, -0.0221],\n",
       "        [-0.0346,  0.0478,  0.0862, -0.0091],\n",
       "        [ 0.0002, -0.0145,  0.0297, -0.0296],\n",
       "        [-0.0420,  0.0294,  0.0633, -0.0138],\n",
       "        [-0.0422,  0.0243,  0.0829,  0.0174],\n",
       "        [-0.0245,  0.0078,  0.0496, -0.0455],\n",
       "        [-0.0442,  0.0306,  0.0611, -0.0483],\n",
       "        [-0.0473,  0.0219,  0.0683, -0.0091],\n",
       "        [-0.0275,  0.0421,  0.0619, -0.0155],\n",
       "        [-0.0723,  0.0208,  0.0802, -0.0171],\n",
       "        [-0.0230,  0.0296,  0.0608, -0.0578],\n",
       "        [-0.0385,  0.0338,  0.0639, -0.0258]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.ones((16,3,224,224))\n",
    "\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"min\", patience=4, factor=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20 \n",
      " Training loss: 0.8047004469986125 - Other training metrics: \n",
      "{'accuracy_score': 0.4227467811158798, 'f1_score': 0.25096319572625064}\n",
      " \n",
      " Validation loss : 0.6689571408882673 - Other validation metrics:\n",
      "{'accuracy_score': 0.5064377682403434, 'f1_score': 0.3217659533449007}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.5064377682403434===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [05:42<1:48:18, 342.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 20 \n",
      " Training loss: 0.6273431765163405 - Other training metrics: \n",
      "{'accuracy_score': 0.6008583690987125, 'f1_score': 0.4454368803707521}\n",
      " \n",
      " Validation loss : 0.5125923054732479 - Other validation metrics:\n",
      "{'accuracy_score': 0.6781115879828327, 'f1_score': 0.6321868692944117}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.6781115879828327===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [11:25<1:42:55, 343.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 20 \n",
      " Training loss: 0.5030808414256623 - Other training metrics: \n",
      "{'accuracy_score': 0.6931330472103004, 'f1_score': 0.6332702393188109}\n",
      " \n",
      " Validation loss : 0.4229069132149987 - Other validation metrics:\n",
      "{'accuracy_score': 0.7253218884120172, 'f1_score': 0.6084157898341498}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7253218884120172===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [17:05<1:36:48, 341.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 20 \n",
      " Training loss: 0.4145816842757581 - Other training metrics: \n",
      "{'accuracy_score': 0.7575107296137339, 'f1_score': 0.6955517782523043}\n",
      " \n",
      " Validation loss : 0.4076788737858314 - Other validation metrics:\n",
      "{'accuracy_score': 0.7424892703862661, 'f1_score': 0.68358310366191}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7424892703862661===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [28:31<1:25:35, 342.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 20 \n",
      " Training loss: 0.3756839537057754 - Other training metrics: \n",
      "{'accuracy_score': 0.7821888412017167, 'f1_score': 0.7302191929866847}\n",
      " \n",
      " Validation loss : 0.5121931935712504 - Other validation metrics:\n",
      "{'accuracy_score': 0.6695278969957081, 'f1_score': 0.6317099567099568}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.6695278969957081===> No saving\n",
      "Epoch 6 / 20 \n",
      " Training loss: 0.3581421581204869 - Other training metrics: \n",
      "{'accuracy_score': 0.7886266094420601, 'f1_score': 0.7392784074877381}\n",
      " \n",
      " Validation loss : 0.40168410426109646 - Other validation metrics:\n",
      "{'accuracy_score': 0.7811158798283262, 'f1_score': 0.6810851894521249}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7811158798283262===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [39:35<1:12:53, 336.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 20 \n",
      " Training loss: 0.2963470094577437 - Other training metrics: \n",
      "{'accuracy_score': 0.8369098712446352, 'f1_score': 0.8117820234230939}\n",
      " \n",
      " Validation loss : 0.469728731450349 - Other validation metrics:\n",
      "{'accuracy_score': 0.7339055793991416, 'f1_score': 0.6219847268146748}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7339055793991416===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [45:03<1:06:44, 333.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 20 \n",
      " Training loss: 0.24746011958613418 - Other training metrics: \n",
      "{'accuracy_score': 0.8755364806866953, 'f1_score': 0.8481946953071255}\n",
      " \n",
      " Validation loss : 0.44753316398150417 - Other validation metrics:\n",
      "{'accuracy_score': 0.776824034334764, 'f1_score': 0.7418253388402642}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.776824034334764===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [50:35<1:01:05, 333.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 20 \n",
      " Training loss: 0.2578566312598057 - Other training metrics: \n",
      "{'accuracy_score': 0.869098712446352, 'f1_score': 0.8486148633860737}\n",
      " \n",
      " Validation loss : 0.6101377583048886 - Other validation metrics:\n",
      "{'accuracy_score': 0.6824034334763949, 'f1_score': 0.6115453325646364}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.6824034334763949===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [56:11<55:41, 334.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 20 \n",
      " Training loss: 0.21664807395489943 - Other training metrics: \n",
      "{'accuracy_score': 0.8830472103004292, 'f1_score': 0.8719834217721676}\n",
      " \n",
      " Validation loss : 0.45316454956843616 - Other validation metrics:\n",
      "{'accuracy_score': 0.7296137339055794, 'f1_score': 0.7066157662196728}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7296137339055794===> No saving\n",
      "Epoch 11 / 20 \n",
      " Training loss: 0.19964106329776699 - Other training metrics: \n",
      "{'accuracy_score': 0.8991416309012875, 'f1_score': 0.8790831239607033}\n",
      " \n",
      " Validation loss : 0.3691509143317462 - Other validation metrics:\n",
      "{'accuracy_score': 0.7939914163090128, 'f1_score': 0.7503938832252084}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7939914163090128===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [1:07:13<44:19, 332.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 20 \n",
      " Training loss: 0.1836360156568079 - Other training metrics: \n",
      "{'accuracy_score': 0.9034334763948498, 'f1_score': 0.8966443389803358}\n",
      " \n",
      " Validation loss : 0.4236522679389035 - Other validation metrics:\n",
      "{'accuracy_score': 0.7510729613733905, 'f1_score': 0.7142670226447835}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7510729613733905===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [1:12:42<38:38, 331.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 20 \n",
      " Training loss: 0.13800659305675858 - Other training metrics: \n",
      "{'accuracy_score': 0.9291845493562232, 'f1_score': 0.9203267956824868}\n",
      " \n",
      " Validation loss : 0.5221005141447286 - Other validation metrics:\n",
      "{'accuracy_score': 0.7253218884120172, 'f1_score': 0.6884223862019915}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7253218884120172===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [1:18:13<33:06, 331.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 20 \n",
      " Training loss: 0.1709204516473502 - Other training metrics: \n",
      "{'accuracy_score': 0.9130901287553648, 'f1_score': 0.9168974793695839}\n",
      " \n",
      " Validation loss : 0.4635371682853658 - Other validation metrics:\n",
      "{'accuracy_score': 0.7296137339055794, 'f1_score': 0.6946640036262679}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7296137339055794===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [1:23:41<27:31, 330.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 20 \n",
      " Training loss: 0.11867752696023734 - Other training metrics: \n",
      "{'accuracy_score': 0.9377682403433476, 'f1_score': 0.9273323921662862}\n",
      " \n",
      " Validation loss : 0.5055141390617057 - Other validation metrics:\n",
      "{'accuracy_score': 0.7553648068669528, 'f1_score': 0.7095354850307161}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7553648068669528===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [1:29:13<22:03, 330.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 20 \n",
      " Training loss: 0.1273695204982558 - Other training metrics: \n",
      "{'accuracy_score': 0.9377682403433476, 'f1_score': 0.9305656226380762}\n",
      " \n",
      " Validation loss : 0.4161818138615512 - Other validation metrics:\n",
      "{'accuracy_score': 0.7639484978540773, 'f1_score': 0.7180316742081447}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7639484978540773===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [1:34:40<16:29, 329.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 20 \n",
      " Training loss: 0.09890596836389647 - Other training metrics: \n",
      "{'accuracy_score': 0.9527896995708155, 'f1_score': 0.9530894098671204}\n",
      " \n",
      " Validation loss : 0.43748524554809276 - Other validation metrics:\n",
      "{'accuracy_score': 0.7811158798283262, 'f1_score': 0.7235129068462403}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7811158798283262===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [1:40:08<10:58, 329.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 20 \n",
      " Training loss: 0.08290231240265743 - Other training metrics: \n",
      "{'accuracy_score': 0.9624463519313304, 'f1_score': 0.9651206966170065}\n",
      " \n",
      " Validation loss : 0.47945385004189905 - Other validation metrics:\n",
      "{'accuracy_score': 0.7682403433476395, 'f1_score': 0.6996395415899238}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7682403433476395===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [1:45:39<05:29, 329.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 20 \n",
      " Training loss: 0.05064674750242239 - Other training metrics: \n",
      "{'accuracy_score': 0.9774678111587983, 'f1_score': 0.9805298821710972}\n",
      " \n",
      " Validation loss : 0.3978147612237112 - Other validation metrics:\n",
      "{'accuracy_score': 0.7854077253218884, 'f1_score': 0.7572505195948658}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7854077253218884===> No saving\n",
      "Epoch 20 / 20 \n",
      " Training loss: 0.07171264170497144 - Other training metrics: \n",
      "{'accuracy_score': 0.9635193133047211, 'f1_score': 0.9692297927986743}\n",
      " \n",
      " Validation loss : 0.4140832553030084 - Other validation metrics:\n",
      "{'accuracy_score': 0.7982832618025751, 'f1_score': 0.7571345237760115}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.7982832618025751===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [1:51:11<00:00, 333.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epoch = 20\n",
    "best_val_acc = 0.0\n",
    "import logging\n",
    "import numpy as np\n",
    "print(\"begin training process\")\n",
    "for i in tqdm(range(0, num_epoch)):\n",
    "    loss, val_loss, train_result, val_result = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_metrics,\n",
    "        val_metrics,\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "#     scheduler.step()\n",
    "    print(\n",
    "        \"Epoch {} / {} \\n Training loss: {} - Other training metrics: \".format(\n",
    "            i + 1, num_epoch, loss\n",
    "        )\n",
    "    )\n",
    "    print(train_result)\n",
    "    print(\n",
    "        \" \\n Validation loss : {} - Other validation metrics:\".format(val_loss)\n",
    "    )\n",
    "    print(val_result)\n",
    "    print(\"\\n\")\n",
    "    # saving epoch with best validation accuracy\n",
    "    if (loss<0.04):\n",
    "        # no saving\n",
    "        continue\n",
    "    if best_val_acc < float(val_result[\"accuracy_score\"]):\n",
    "        print(\n",
    "            \"Validation accuracy= \"+\n",
    "            str(val_result[\"accuracy_score\"])+\n",
    "            \"===> Save best epoch\"\n",
    "        )\n",
    "        best_val_acc = val_result[\"accuracy_score\"]\n",
    "        torch.save(\n",
    "            model,\n",
    "            \"./\" +  \"best.pt\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Validation accuracy= \"+ str(val_result[\"accuracy_score\"])+ \"===> No saving\"\n",
    "        )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(model, test_loader,name='no_tta_prob.npy'):\n",
    "    # testing the model by turning model \"Eval\" mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    aprobs = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "            output = model(data)\n",
    "            prob = nn.Softmax(dim=1)\n",
    "            # applying Softmax to results\n",
    "            probs = prob(output)\n",
    "            aprobs.append(probs.cpu())\n",
    "            labels.append(target.cpu().numpy())\n",
    "            preds.extend(torch.argmax(probs, axis=1).tolist())\n",
    "    aprobs = np.array(aprobs)\n",
    "    np.save(name,aprobs)\n",
    "    return preds, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  aprobs = np.array(aprobs)\n",
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  aprobs = np.array(aprobs)\n"
     ]
    }
   ],
   "source": [
    "preds,labels =test_result(test_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       103\n",
      "           1       0.72      0.82      0.76       127\n",
      "           2       0.40      0.39      0.39        36\n",
      "           3       0.74      0.54      0.62        26\n",
      "\n",
      "    accuracy                           0.72       292\n",
      "   macro avg       0.68      0.63      0.65       292\n",
      "weighted avg       0.73      0.72      0.72       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as rp\n",
    "print(rp(labels,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\3807167902.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(train_data[1],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data[1],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_102.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>levle3_9.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>levle3_91.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>levle3_93.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>levle3_95.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>levle3_97.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                path  label  leisons\n",
       "0       levle0_0.jpg      0        3\n",
       "1       levle0_1.jpg      0        3\n",
       "2     levle0_100.jpg      0        2\n",
       "3     levle0_101.jpg      0        1\n",
       "4     levle0_102.jpg      0        3\n",
       "...              ...    ...      ...\n",
       "1160    levle3_9.jpg      3       65\n",
       "1161   levle3_91.jpg      3       58\n",
       "1162   levle3_93.jpg      3       61\n",
       "1163   levle3_95.jpg      3       59\n",
       "1164   levle3_97.jpg      3       63\n",
       "\n",
       "[1165 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = data_split(train_df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\4252433160.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv(test_data[1],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_data[1],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_60.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_483.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_110.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_404.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_155.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>levle3_37.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>levle3_109.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>levle3_76.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>levle3_113.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>levle3_30.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  label  leisons\n",
       "0     levle0_60.jpg      0        1\n",
       "1    levle0_483.jpg      0        2\n",
       "2    levle0_110.jpg      0        2\n",
       "3    levle0_404.jpg      0        1\n",
       "4    levle0_155.jpg      0        1\n",
       "..              ...    ...      ...\n",
       "287   levle3_37.jpg      3       55\n",
       "288  levle3_109.jpg      3       52\n",
       "289   levle3_76.jpg      3       56\n",
       "290  levle3_113.jpg      3       64\n",
       "291   levle3_30.jpg      3       53\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                            torchvision.transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images left-right\n",
    "                            torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "                            torchvision.transforms.RandomRotation(degrees=15),\n",
    "                                            torchvision.transforms.ElasticTransform(),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])\n",
    "test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Classification_Dataset(x_train,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=transform,training=True)\n",
    "val_dataset = Classification_Dataset(x_val,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "    )\n",
    "    # create test_loader\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Classification_Dataset(test_df,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=1, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = Metrics([\"accuracy_score\",\"f1_score\"])\n",
    "val_metrics = Metrics([\"accuracy_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10 \n",
      " Training loss: 0.23553761654401542 - Other training metrics: \n",
      "{'accuracy_score': 0.8798283261802575, 'f1_score': 0.8639048489625796}\n",
      " \n",
      " Validation loss : 0.17254476741659794 - Other validation metrics:\n",
      "{'accuracy_score': 0.9012875536480687, 'f1_score': 0.8963823655264417}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9012875536480687===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [14:39<57:25, 430.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10 \n",
      " Training loss: 0.17336342029689208 - Other training metrics: \n",
      "{'accuracy_score': 0.9066523605150214, 'f1_score': 0.8988772469519628}\n",
      " \n",
      " Validation loss : 0.19005355597053986 - Other validation metrics:\n",
      "{'accuracy_score': 0.8927038626609443, 'f1_score': 0.8811063709128073}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.8927038626609443===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [19:59<44:18, 379.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10 \n",
      " Training loss: 0.13317305083054842 - Other training metrics: \n",
      "{'accuracy_score': 0.9356223175965666, 'f1_score': 0.9332716734001965}\n",
      " \n",
      " Validation loss : 0.21130798753878588 - Other validation metrics:\n",
      "{'accuracy_score': 0.8927038626609443, 'f1_score': 0.8769419306184012}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.8927038626609443===> No saving\n",
      "Epoch 4 / 10 \n",
      " Training loss: 0.11610275996217401 - Other training metrics: \n",
      "{'accuracy_score': 0.9356223175965666, 'f1_score': 0.9286470772032118}\n",
      " \n",
      " Validation loss : 0.19267959462662623 - Other validation metrics:\n",
      "{'accuracy_score': 0.9055793991416309, 'f1_score': 0.8941348003848003}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9055793991416309===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [30:46<28:47, 345.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10 \n",
      " Training loss: 0.09835338664876672 - Other training metrics: \n",
      "{'accuracy_score': 0.9517167381974249, 'f1_score': 0.9534671420171575}\n",
      " \n",
      " Validation loss : 0.22715936394911979 - Other validation metrics:\n",
      "{'accuracy_score': 0.8841201716738197, 'f1_score': 0.8699166291173517}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.8841201716738197===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [36:13<22:36, 339.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10 \n",
      " Training loss: 0.08413633174570717 - Other training metrics: \n",
      "{'accuracy_score': 0.9592274678111588, 'f1_score': 0.9572474354486833}\n",
      " \n",
      " Validation loss : 0.1829496199672826 - Other validation metrics:\n",
      "{'accuracy_score': 0.8841201716738197, 'f1_score': 0.8705656626358439}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.8841201716738197===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [41:39<16:44, 334.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10 \n",
      " Training loss: 0.07862247027009087 - Other training metrics: \n",
      "{'accuracy_score': 0.9592274678111588, 'f1_score': 0.9502472631693042}\n",
      " \n",
      " Validation loss : 0.1942059092639342 - Other validation metrics:\n",
      "{'accuracy_score': 0.9055793991416309, 'f1_score': 0.8985372377682244}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9055793991416309===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [47:07<11:05, 332.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10 \n",
      " Training loss: 0.0702551011587673 - Other training metrics: \n",
      "{'accuracy_score': 0.973175965665236, 'f1_score': 0.9785981150445221}\n",
      " \n",
      " Validation loss : 0.14229219234168786 - Other validation metrics:\n",
      "{'accuracy_score': 0.9184549356223176, 'f1_score': 0.9144462818104977}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9184549356223176===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [52:39<05:32, 332.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10 \n",
      " Training loss: 0.07076271866396261 - Other training metrics: \n",
      "{'accuracy_score': 0.9656652360515021, 'f1_score': 0.9679728224178784}\n",
      " \n",
      " Validation loss : 0.1498966107840446 - Other validation metrics:\n",
      "{'accuracy_score': 0.9184549356223176, 'f1_score': 0.9189975334742776}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9184549356223176===> No saving\n",
      "Epoch 10 / 10 \n",
      " Training loss: 0.05902129135897999 - Other training metrics: \n",
      "{'accuracy_score': 0.9753218884120172, 'f1_score': 0.9735185727335947}\n",
      " \n",
      " Validation loss : 0.1511761919623281 - Other validation metrics:\n",
      "{'accuracy_score': 0.9227467811158798, 'f1_score': 0.9223620127477872}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9227467811158798===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [57:59<00:00, 347.96s/it]\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epoch = 10\n",
    "best_val_acc = 0.0\n",
    "import logging\n",
    "import numpy as np\n",
    "print(\"begin training process\")\n",
    "for i in tqdm(range(0, num_epoch)):\n",
    "    loss, val_loss, train_result, val_result = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_metrics,\n",
    "        val_metrics,\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "#     scheduler.step()\n",
    "    print(\n",
    "        \"Epoch {} / {} \\n Training loss: {} - Other training metrics: \".format(\n",
    "            i + 1, num_epoch, loss\n",
    "        )\n",
    "    )\n",
    "    print(train_result)\n",
    "    print(\n",
    "        \" \\n Validation loss : {} - Other validation metrics:\".format(val_loss)\n",
    "    )\n",
    "    print(val_result)\n",
    "    print(\"\\n\")\n",
    "    # saving epoch with best validation accuracy\n",
    "    if (loss<0.04):\n",
    "        # no saving\n",
    "        continue\n",
    "    if best_val_acc < float(val_result[\"accuracy_score\"]):\n",
    "        print(\n",
    "            \"Validation accuracy= \"+\n",
    "            str(val_result[\"accuracy_score\"])+\n",
    "            \"===> Save best epoch\"\n",
    "        )\n",
    "        best_val_acc = val_result[\"accuracy_score\"]\n",
    "        torch.save(\n",
    "            model,\n",
    "            \"./\" +  \"best.pt\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Validation accuracy= \"+ str(val_result[\"accuracy_score\"])+ \"===> No saving\"\n",
    "        )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  aprobs = np.array(aprobs)\n",
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  aprobs = np.array(aprobs)\n"
     ]
    }
   ],
   "source": [
    "preds_1,labels_1 = test_result(test_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       107\n",
      "           1       0.94      0.98      0.96       122\n",
      "           2       0.92      0.89      0.90        37\n",
      "           3       0.92      0.92      0.92        26\n",
      "\n",
      "    accuracy                           0.95       292\n",
      "   macro avg       0.94      0.93      0.94       292\n",
      "weighted avg       0.95      0.95      0.95       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rp(preds_1,labels_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\2371486086.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(train_data[2],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data[2],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_102.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>levle3_93.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>levle3_94.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>levle3_95.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>levle3_96.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>levle3_97.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                path  label  leisons\n",
       "0       levle0_0.jpg      0        3\n",
       "1     levle0_100.jpg      0        2\n",
       "2     levle0_101.jpg      0        1\n",
       "3     levle0_102.jpg      0        3\n",
       "4     levle0_103.jpg      0        2\n",
       "...              ...    ...      ...\n",
       "1160   levle3_93.jpg      3       61\n",
       "1161   levle3_94.jpg      3       57\n",
       "1162   levle3_95.jpg      3       51\n",
       "1163   levle3_96.jpg      3       55\n",
       "1164   levle3_97.jpg      3       61\n",
       "\n",
       "[1165 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = data_split(train_df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1489905983.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv(test_data[2],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_data[2],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_426.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_382.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_517.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_115.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_338.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>levle3_26.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>levle3_87.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>levle3_19.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>levle3_9.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>levle3_13.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  label  leisons\n",
       "0    levle0_426.jpg      0        2\n",
       "1    levle0_382.jpg      0        4\n",
       "2    levle0_517.jpg      0        3\n",
       "3    levle0_115.jpg      0        1\n",
       "4    levle0_338.jpg      0        1\n",
       "..              ...    ...      ...\n",
       "287   levle3_26.jpg      3       55\n",
       "288   levle3_87.jpg      3       56\n",
       "289   levle3_19.jpg      3       57\n",
       "290    levle3_9.jpg      3       65\n",
       "291   levle3_13.jpg      3       54\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                            torchvision.transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip images left-right\n",
    "                            torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "                            torchvision.transforms.RandomRotation(degrees=15),\n",
    "                                            torchvision.transforms.ElasticTransform(),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])\n",
    "test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Classification_Dataset(x_train,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=transform,training=True)\n",
    "val_dataset = Classification_Dataset(x_val,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "    )\n",
    "    # create test_loader\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Classification_Dataset(test_df,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=1, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 8 \n",
      " Training loss: 0.11493869910872034 - Other training metrics: \n",
      "{'accuracy_score': 0.9399141630901288, 'f1_score': 0.933736726721598}\n",
      " \n",
      " Validation loss : 0.07604187256916398 - Other validation metrics:\n",
      "{'accuracy_score': 0.9613733905579399, 'f1_score': 0.9593689096255255}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9613733905579399===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [10:40<31:59, 319.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 8 \n",
      " Training loss: 0.08470647704943439 - Other training metrics: \n",
      "{'accuracy_score': 0.9603004291845494, 'f1_score': 0.9532924973351192}\n",
      " \n",
      " Validation loss : 0.0865488896074469 - Other validation metrics:\n",
      "{'accuracy_score': 0.9570815450643777, 'f1_score': 0.952295918367347}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9570815450643777===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [15:59<26:36, 319.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 8 \n",
      " Training loss: 0.07792447359089304 - Other training metrics: \n",
      "{'accuracy_score': 0.9645922746781116, 'f1_score': 0.9647815770526458}\n",
      " \n",
      " Validation loss : 0.06612029310331836 - Other validation metrics:\n",
      "{'accuracy_score': 0.9613733905579399, 'f1_score': 0.955025256901015}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9613733905579399===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [29:07<33:37, 504.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 8 \n",
      " Training loss: 0.07415643088967247 - Other training metrics: \n",
      "{'accuracy_score': 0.9645922746781116, 'f1_score': 0.9661654897966969}\n",
      " \n",
      " Validation loss : 0.08379099156723514 - Other validation metrics:\n",
      "{'accuracy_score': 0.9570815450643777, 'f1_score': 0.9522623312647943}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9570815450643777===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [1:06:38<56:42, 1134.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 8 \n",
      " Training loss: 0.06129266596659059 - Other training metrics: \n",
      "{'accuracy_score': 0.9699570815450643, 'f1_score': 0.9739261763215888}\n",
      " \n",
      " Validation loss : 0.08141198883816408 - Other validation metrics:\n",
      "{'accuracy_score': 0.9570815450643777, 'f1_score': 0.9565947759757573}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9570815450643777===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [1:43:05<49:44, 1492.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 8 \n",
      " Training loss: 0.06763697720568451 - Other training metrics: \n",
      "{'accuracy_score': 0.9688841201716738, 'f1_score': 0.9736606610530041}\n",
      " \n",
      " Validation loss : 0.08622069618476819 - Other validation metrics:\n",
      "{'accuracy_score': 0.9570815450643777, 'f1_score': 0.9565940574451854}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9570815450643777===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [2:20:21<28:55, 1735.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 8 \n",
      " Training loss: 0.0609141271121704 - Other training metrics: \n",
      "{'accuracy_score': 0.9656652360515021, 'f1_score': 0.9678269098030382}\n",
      " \n",
      " Validation loss : 0.07849532688764031 - Other validation metrics:\n",
      "{'accuracy_score': 0.9570815450643777, 'f1_score': 0.9522822299651568}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9570815450643777===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [2:57:52<00:00, 1334.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 8 \n",
      " Training loss: 0.0448160262762413 - Other training metrics: \n",
      "{'accuracy_score': 0.9785407725321889, 'f1_score': 0.9793734671536439}\n",
      " \n",
      " Validation loss : 0.0864113770872994 - Other validation metrics:\n",
      "{'accuracy_score': 0.9613733905579399, 'f1_score': 0.9623278406414336}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9613733905579399===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epoch = 8\n",
    "best_val_acc = 0.0\n",
    "import logging\n",
    "import numpy as np\n",
    "print(\"begin training process\")\n",
    "for i in tqdm(range(0, num_epoch)):\n",
    "    loss, val_loss, train_result, val_result = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_metrics,\n",
    "        val_metrics,\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "#     scheduler.step()\n",
    "    print(\n",
    "        \"Epoch {} / {} \\n Training loss: {} - Other training metrics: \".format(\n",
    "            i + 1, num_epoch, loss\n",
    "        )\n",
    "    )\n",
    "    print(train_result)\n",
    "    print(\n",
    "        \" \\n Validation loss : {} - Other validation metrics:\".format(val_loss)\n",
    "    )\n",
    "    print(val_result)\n",
    "    print(\"\\n\")\n",
    "    # saving epoch with best validation accuracy\n",
    "    if (loss<0.04):\n",
    "        # no saving\n",
    "        continue\n",
    "    if best_val_acc < float(val_result[\"accuracy_score\"]):\n",
    "        print(\n",
    "            \"Validation accuracy= \"+\n",
    "            str(val_result[\"accuracy_score\"])+\n",
    "            \"===> Save best epoch\"\n",
    "        )\n",
    "        best_val_acc = val_result[\"accuracy_score\"]\n",
    "        torch.save(\n",
    "            model,\n",
    "            \"./\" +  \"best.pt\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Validation accuracy= \"+ str(val_result[\"accuracy_score\"])+ \"===> No saving\"\n",
    "        )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  aprobs = np.array(aprobs)\n",
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  aprobs = np.array(aprobs)\n"
     ]
    }
   ],
   "source": [
    "preds_2,labels_2 =test_result(test_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rp(preds_2,labels_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\975574921.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(train_data[3],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data[3],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_102.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_104.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>levle3_91.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>levle3_92.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>levle3_94.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>levle3_96.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>levle3_97.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                path  label  leisons\n",
       "0       levle0_1.jpg      0        3\n",
       "1     levle0_100.jpg      0        2\n",
       "2     levle0_102.jpg      0        3\n",
       "3     levle0_103.jpg      0        2\n",
       "4     levle0_104.jpg      0        1\n",
       "...              ...    ...      ...\n",
       "1160   levle3_91.jpg      3       52\n",
       "1161   levle3_92.jpg      3       57\n",
       "1162   levle3_94.jpg      3       65\n",
       "1163   levle3_96.jpg      3       57\n",
       "1164   levle3_97.jpg      3       55\n",
       "\n",
       "[1165 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = data_split(train_df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>leisons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levle0_426.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>levle0_382.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>levle0_517.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>levle0_115.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>levle0_338.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>levle3_26.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>levle3_87.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>levle3_19.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>levle3_9.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>levle3_13.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  label  leisons\n",
       "0    levle0_426.jpg      0        2\n",
       "1    levle0_382.jpg      0        4\n",
       "2    levle0_517.jpg      0        3\n",
       "3    levle0_115.jpg      0        1\n",
       "4    levle0_338.jpg      0        1\n",
       "..              ...    ...      ...\n",
       "287   levle3_26.jpg      3       55\n",
       "288   levle3_87.jpg      3       56\n",
       "289   levle3_19.jpg      3       57\n",
       "290    levle3_9.jpg      3       65\n",
       "291   levle3_13.jpg      3       54\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Classification_Dataset(x_train,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=transform,training=True)\n",
    "val_dataset = Classification_Dataset(x_val,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "    )\n",
    "    # create test_loader\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Classification_Dataset(test_df,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=1, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = Metrics([\"accuracy_score\",\"f1_score\"])\n",
    "val_metrics = Metrics([\"accuracy_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 8 \n",
      " Training loss: 0.0501968581948925 - Other training metrics: \n",
      "{'accuracy_score': 0.9774678111587983, 'f1_score': 0.9769535920873927}\n",
      " \n",
      " Validation loss : 0.0316298113168565 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [10:34<31:45, 317.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 8 \n",
      " Training loss: 0.05738462724567035 - Other training metrics: \n",
      "{'accuracy_score': 0.9688841201716738, 'f1_score': 0.9772371368127961}\n",
      " \n",
      " Validation loss : 0.033171262160391256 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [15:56<26:40, 320.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 8 \n",
      " Training loss: 0.04126280978873628 - Other training metrics: \n",
      "{'accuracy_score': 0.9828326180257511, 'f1_score': 0.9841798053806067}\n",
      " \n",
      " Validation loss : 0.034229109039761986 - Other validation metrics:\n",
      "{'accuracy_score': 0.9871244635193133, 'f1_score': 0.9815563670004147}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9871244635193133===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [21:18<21:22, 320.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 8 \n",
      " Training loss: 0.04179007819426034 - Other training metrics: \n",
      "{'accuracy_score': 0.9839055793991416, 'f1_score': 0.9869288862951903}\n",
      " \n",
      " Validation loss : 0.03172700922504515 - Other validation metrics:\n",
      "{'accuracy_score': 0.9871244635193133, 'f1_score': 0.9815563670004147}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9871244635193133===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [26:39<16:02, 320.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 8 \n",
      " Training loss: 0.049453988239616796 - Other training metrics: \n",
      "{'accuracy_score': 0.9796137339055794, 'f1_score': 0.9790577264189405}\n",
      " \n",
      " Validation loss : 0.03300052561473437 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [32:00<10:41, 320.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 8 \n",
      " Training loss: 0.0448490123328445 - Other training metrics: \n",
      "{'accuracy_score': 0.9796137339055794, 'f1_score': 0.9808956429066245}\n",
      " \n",
      " Validation loss : 0.03441809001078933 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [37:21<05:20, 320.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 8 \n",
      " Training loss: 0.04145666221836222 - Other training metrics: \n",
      "{'accuracy_score': 0.9817596566523605, 'f1_score': 0.9809516049731535}\n",
      " \n",
      " Validation loss : 0.03362672676855914 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [42:42<00:00, 320.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 8 \n",
      " Training loss: 0.043006054335573585 - Other training metrics: \n",
      "{'accuracy_score': 0.9839055793991416, 'f1_score': 0.9876023999728817}\n",
      " \n",
      " Validation loss : 0.03670686150825075 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9870348121744628}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epoch = 8\n",
    "best_val_acc = 0.0\n",
    "import logging\n",
    "import numpy as np\n",
    "print(\"begin training process\")\n",
    "for i in tqdm(range(0, num_epoch)):\n",
    "    loss, val_loss, train_result, val_result = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_metrics,\n",
    "        val_metrics,\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "#     scheduler.step()\n",
    "    print(\n",
    "        \"Epoch {} / {} \\n Training loss: {} - Other training metrics: \".format(\n",
    "            i + 1, num_epoch, loss\n",
    "        )\n",
    "    )\n",
    "    print(train_result)\n",
    "    print(\n",
    "        \" \\n Validation loss : {} - Other validation metrics:\".format(val_loss)\n",
    "    )\n",
    "    print(val_result)\n",
    "    print(\"\\n\")\n",
    "    # saving epoch with best validation accuracy\n",
    "    if (loss<0.04):\n",
    "        # no saving\n",
    "        continue\n",
    "    if best_val_acc < float(val_result[\"accuracy_score\"]):\n",
    "        print(\n",
    "            \"Validation accuracy= \"+\n",
    "            str(val_result[\"accuracy_score\"])+\n",
    "            \"===> Save best epoch\"\n",
    "        )\n",
    "        best_val_acc = val_result[\"accuracy_score\"]\n",
    "        torch.save(\n",
    "            model,\n",
    "            \"./\" +  \"best.pt\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Validation accuracy= \"+ str(val_result[\"accuracy_score\"])+ \"===> No saving\"\n",
    "        )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  aprobs = np.array(aprobs)\n",
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  aprobs = np.array(aprobs)\n"
     ]
    }
   ],
   "source": [
    "test_model = torch.load(\"best.pt\")\n",
    "preds_3,labels_3 =test_result(test_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       101\n",
      "           1       1.00      0.98      0.99       130\n",
      "           2       0.94      1.00      0.97        34\n",
      "           3       1.00      0.96      0.98        27\n",
      "\n",
      "    accuracy                           0.99       292\n",
      "   macro avg       0.98      0.98      0.98       292\n",
      "weighted avg       0.99      0.99      0.99       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rp(preds_3,labels_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1650634807.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_df = pd.read_csv(train_data[4],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data[4],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = data_split(train_df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\4220881812.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_df = pd.read_csv(test_data[4],names=['path','label','leisons'],sep='  ')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_data[4],names=['path','label','leisons'],sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Classification_Dataset(x_train,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=transform,training=True)\n",
    "val_dataset = Classification_Dataset(x_val,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "    )\n",
    "    # create test_loader\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Classification_Dataset(test_df,data_path = \"../data-collection/dataset/acne-severity/JPEGImages\",transform=test_transform,training=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=1, shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = Metrics([\"accuracy_score\",\"f1_score\"])\n",
    "val_metrics = Metrics([\"accuracy_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 8 \n",
      " Training loss: 0.049775041815676914 - Other training metrics: \n",
      "{'accuracy_score': 0.9763948497854077, 'f1_score': 0.9787720324161091}\n",
      " \n",
      " Validation loss : 0.0235369814631765 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9889040628200751}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [10:48<32:26, 324.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 8 \n",
      " Training loss: 0.04119120356766707 - Other training metrics: \n",
      "{'accuracy_score': 0.9828326180257511, 'f1_score': 0.9843343250776654}\n",
      " \n",
      " Validation loss : 0.024493591995837862 - Other validation metrics:\n",
      "{'accuracy_score': 0.9871244635193133, 'f1_score': 0.986150986732751}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9871244635193133===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [16:13<27:01, 324.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 8 \n",
      " Training loss: 0.04296286695920602 - Other training metrics: \n",
      "{'accuracy_score': 0.9817596566523605, 'f1_score': 0.983062618594266}\n",
      " \n",
      " Validation loss : 0.020646090079658532 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9889040628200751}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [21:37<21:37, 324.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 8 \n",
      " Training loss: 0.04019469311141085 - Other training metrics: \n",
      "{'accuracy_score': 0.9839055793991416, 'f1_score': 0.9863852155055227}\n",
      " \n",
      " Validation loss : 0.020135007063206686 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9889040628200751}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9914163090128756===> No saving\n",
      "Epoch 5 / 8 \n",
      " Training loss: 0.04173472063823767 - Other training metrics: \n",
      "{'accuracy_score': 0.9785407725321889, 'f1_score': 0.9822501170327258}\n",
      " \n",
      " Validation loss : 0.02056679676402792 - Other validation metrics:\n",
      "{'accuracy_score': 0.9957081545064378, 'f1_score': 0.9943825079941232}\n",
      "\n",
      "\n",
      "Validation accuracy= 0.9957081545064378===> Save best epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [32:19<10:45, 322.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 8 \n",
      " Training loss: 0.0383300655201685 - Other training metrics: \n",
      "{'accuracy_score': 0.9871244635193133, 'f1_score': 0.9896696924307774}\n",
      " \n",
      " Validation loss : 0.02354261386228222 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9916293123642741}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [37:42<05:22, 322.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 8 \n",
      " Training loss: 0.03245136943993522 - Other training metrics: \n",
      "{'accuracy_score': 0.990343347639485, 'f1_score': 0.9911927348697956}\n",
      " \n",
      " Validation loss : 0.021016685428025896 - Other validation metrics:\n",
      "{'accuracy_score': 0.9914163090128756, 'f1_score': 0.9889040628200751}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [43:04<00:00, 323.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 8 \n",
      " Training loss: 0.03661893569972254 - Other training metrics: \n",
      "{'accuracy_score': 0.9860515021459227, 'f1_score': 0.9889802297133379}\n",
      " \n",
      " Validation loss : 0.0202250503035574 - Other validation metrics:\n",
      "{'accuracy_score': 0.9957081545064378, 'f1_score': 0.9943825079941232}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_epoch = 8\n",
    "best_val_acc = 0.0\n",
    "import logging\n",
    "import numpy as np\n",
    "print(\"begin training process\")\n",
    "for i in tqdm(range(0, num_epoch)):\n",
    "    loss, val_loss, train_result, val_result = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_metrics,\n",
    "        val_metrics,\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "#     scheduler.step()\n",
    "    print(\n",
    "        \"Epoch {} / {} \\n Training loss: {} - Other training metrics: \".format(\n",
    "            i + 1, num_epoch, loss\n",
    "        )\n",
    "    )\n",
    "    print(train_result)\n",
    "    print(\n",
    "        \" \\n Validation loss : {} - Other validation metrics:\".format(val_loss)\n",
    "    )\n",
    "    print(val_result)\n",
    "    print(\"\\n\")\n",
    "    # saving epoch with best validation accuracy\n",
    "    if (loss<0.04):\n",
    "        # no saving\n",
    "        continue\n",
    "    if best_val_acc < float(val_result[\"accuracy_score\"]):\n",
    "        print(\n",
    "            \"Validation accuracy= \"+\n",
    "            str(val_result[\"accuracy_score\"])+\n",
    "            \"===> Save best epoch\"\n",
    "        )\n",
    "        best_val_acc = val_result[\"accuracy_score\"]\n",
    "        torch.save(\n",
    "            model,\n",
    "            \"./\" +  \"best.pt\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Validation accuracy= \"+ str(val_result[\"accuracy_score\"])+ \"===> No saving\"\n",
    "        )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  aprobs = np.array(aprobs)\n",
      "C:\\Users\\prais\\AppData\\Local\\Temp\\ipykernel_21464\\1345960528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  aprobs = np.array(aprobs)\n"
     ]
    }
   ],
   "source": [
    "preds_4,labels_4 =test_result(test_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       103\n",
      "           1       0.98      1.00      0.99       127\n",
      "           2       1.00      0.94      0.97        36\n",
      "           3       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.99       292\n",
      "   macro avg       0.99      0.98      0.99       292\n",
      "weighted avg       0.99      0.99      0.99       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rp(labels_4,preds_4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
